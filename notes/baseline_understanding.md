# Explain the progress and result of yolov5

- **注明：这是跟着b导学习的yolov5，源码来源于b导的github** https://github.com/bubbliiiing/yolov5-pytorch

目录如下

[TOC]



# baseline

## 数据集

数据集，我直接使用原主的voc数据集，且已经写好数据集预处理。

```python
D:\softwear_dl\anaconda\envs\torch1.10\python.exe D:/shuqikaohe/yolov5-pytorch-main/voc_annotation.py
Generate txt in ImageSets.
train and val size 19352
train size 17416
Generate txt in ImageSets done.
Generate 2007_train.txt and 2007_val.txt for train.
Generate 2007_train.txt and 2007_val.txt for train done.
|   aeroplane |  1336 | 
|     bicycle |  1259 | 
|        bird |  1900 | 
|        boat |  1294 | 
|      bottle |  2013 | 
|         bus |   911 | 
|         car |  4025 | 
|         cat |  1768 | 
|       chair |  3497 | 
|         cow |  1012 | 
| diningtable |   922 | 
|         dog |  2222 | 
|       horse |  1287 | 
|   motorbike |  1248 | 
|      person | 16051 | 
| pottedplant |  1784 | 
|       sheep |  1129 | 
|        sofa |   951 | 
|       train |  1086 | 
|   tvmonitor |  1283 | 


```



这是在服务器上报的一个错。torch and

 Couldn't load custom C++ ops. This can happen if your PyTorch and torchvision versions are incompatible, or if you had errors while compiling torchvision from source. For further information on the compatible versions, check https://github.com/pytorch/vision#installation for the compatibility matrix. Please check your PyTorch version with torch.__version__ and your torchvision version with torchvision.__version__ and verify if they are compatible, and if not please reinstall torchvision so that it matches your PyTorch install.



（7月4日）

首先，我们先总网络结构开始。

CSPdarknet 跟yolov3的darknet53网络架构有的很带的改动，不再是简单的残差堆叠，把一个大的残差块，分成四部分，每一部分有一个conv和再次conv后的block堆叠，中间的残差块比较深，两边的较浅，在感受野最大的特征图之前还增加了spp由三个不同的kennel形成的最大池化，相比yolov3，特征提取深度更深。最重要的是是它能够在增加深度的同时，能够保持广度，而且还减少了网络层数，也就意味着减少了参数，使得网络更加轻量化。

然后到yolo_body部分，yolo_body部分增加了csplayer和倒三角的操作，特区到的特征更加充分，同时也增加了网络的复杂度，检测的效果更好。

网络结构如下所示![](D:/shuqikaohe/picture/8.png)

 



（7月5日）

yolo解码

**借鉴出处** https://blog.csdn.net/weixin_45377629/article/details/124144913

再利用darknet和yolobody后得到3个yolo_head的输出，不同尺度之下，每个网格点均有先验框，网络训练过程会对先验框的参数进行调整，进而得到预测框，从不同尺度下预测框还原到原图输入的图像上，同时包括该框内目标预测的结果情况（预测框的位置、类别概率、置信度分数）
<<<<<<< HEAD



## 配置参数

整个网络的执行循序如下：


----------------------------------------------------------------

        Layer (type)               Output Shape         Param #
          
    ​        ================================================================
    ​                Conv2d-1         [-1, 64, 320, 320]           6,912
    ​           BatchNorm2d-2         [-1, 64, 320, 320]             128
    ​                  SiLU-3         [-1, 64, 320, 320]               0
    ​                  Conv-4         [-1, 64, 320, 320]               0
    ​                 Focus-5         [-1, 64, 320, 320]               0
    ​                Conv2d-6        [-1, 128, 160, 160]          73,728
    ​           BatchNorm2d-7        [-1, 128, 160, 160]             256
    ​                  SiLU-8        [-1, 128, 160, 160]               0
    ​                  Conv-9        [-1, 128, 160, 160]               0
    ​               Conv2d-10         [-1, 64, 160, 160]           8,192
    ​          BatchNorm2d-11         [-1, 64, 160, 160]             128
    ​                 SiLU-12         [-1, 64, 160, 160]               0
    ​                 Conv-13         [-1, 64, 160, 160]               0
    ​               Conv2d-14         [-1, 64, 160, 160]           4,096
    ​          BatchNorm2d-15         [-1, 64, 160, 160]             128
    ​                 SiLU-16         [-1, 64, 160, 160]               0
    ​                 Conv-17         [-1, 64, 160, 160]               0
    ​               Conv2d-18         [-1, 64, 160, 160]          36,864
    ​          BatchNorm2d-19         [-1, 64, 160, 160]             128
    ​                 SiLU-20         [-1, 64, 160, 160]               0
    ​                 Conv-21         [-1, 64, 160, 160]               0
    ​           Bottleneck-22         [-1, 64, 160, 160]               0
    ​               Conv2d-23         [-1, 64, 160, 160]           4,096
    ​          BatchNorm2d-24         [-1, 64, 160, 160]             128
    ​                 SiLU-25         [-1, 64, 160, 160]               0
    ​                 Conv-26         [-1, 64, 160, 160]               0
    ​               Conv2d-27         [-1, 64, 160, 160]          36,864
    ​          BatchNorm2d-28         [-1, 64, 160, 160]             128
    ​                 SiLU-29         [-1, 64, 160, 160]               0
    ​                 Conv-30         [-1, 64, 160, 160]               0
    ​           Bottleneck-31         [-1, 64, 160, 160]               0
    ​               Conv2d-32         [-1, 64, 160, 160]           4,096
    ​          BatchNorm2d-33         [-1, 64, 160, 160]             128
    ​                 SiLU-34         [-1, 64, 160, 160]               0
    ​                 Conv-35         [-1, 64, 160, 160]               0
    ​               Conv2d-36         [-1, 64, 160, 160]          36,864
    ​          BatchNorm2d-37         [-1, 64, 160, 160]             128
    ​                 SiLU-38         [-1, 64, 160, 160]               0
    ​                 Conv-39         [-1, 64, 160, 160]               0
    ​           Bottleneck-40         [-1, 64, 160, 160]               0
    ​               Conv2d-41         [-1, 64, 160, 160]           8,192
    ​          BatchNorm2d-42         [-1, 64, 160, 160]             128
    ​                 SiLU-43         [-1, 64, 160, 160]               0
    ​                 Conv-44         [-1, 64, 160, 160]               0
    ​               Conv2d-45        [-1, 128, 160, 160]          16,384
    ​          BatchNorm2d-46        [-1, 128, 160, 160]             256
    ​                 SiLU-47        [-1, 128, 160, 160]               0
    ​                 Conv-48        [-1, 128, 160, 160]               0
    ​                   C3-49        [-1, 128, 160, 160]               0
    ​               Conv2d-50          [-1, 256, 80, 80]         294,912
    ​          BatchNorm2d-51          [-1, 256, 80, 80]             512
    ​                 SiLU-52          [-1, 256, 80, 80]               0
    ​                 Conv-53          [-1, 256, 80, 80]               0
    ​               Conv2d-54          [-1, 128, 80, 80]          32,768
    ​          BatchNorm2d-55          [-1, 128, 80, 80]             256
    ​                 SiLU-56          [-1, 128, 80, 80]               0
    ​                 Conv-57          [-1, 128, 80, 80]               0
    ​               Conv2d-58          [-1, 128, 80, 80]          16,384
    ​          BatchNorm2d-59          [-1, 128, 80, 80]             256
    ​                 SiLU-60          [-1, 128, 80, 80]               0
    ​                 Conv-61          [-1, 128, 80, 80]               0
    ​               Conv2d-62          [-1, 128, 80, 80]         147,456
    ​          BatchNorm2d-63          [-1, 128, 80, 80]             256
    ​                 SiLU-64          [-1, 128, 80, 80]               0
    ​                 Conv-65          [-1, 128, 80, 80]               0
    ​           Bottleneck-66          [-1, 128, 80, 80]               0
    ​               Conv2d-67          [-1, 128, 80, 80]          16,384
    ​          BatchNorm2d-68          [-1, 128, 80, 80]             256
    ​                 SiLU-69          [-1, 128, 80, 80]               0
    ​                 Conv-70          [-1, 128, 80, 80]               0
    ​               Conv2d-71          [-1, 128, 80, 80]         147,456
    ​          BatchNorm2d-72          [-1, 128, 80, 80]             256
    ​                 SiLU-73          [-1, 128, 80, 80]               0
    ​                 Conv-74          [-1, 128, 80, 80]               0
    ​           Bottleneck-75          [-1, 128, 80, 80]               0
    ​               Conv2d-76          [-1, 128, 80, 80]          16,384
    ​          BatchNorm2d-77          [-1, 128, 80, 80]             256
    ​                 SiLU-78          [-1, 128, 80, 80]               0
    ​                 Conv-79          [-1, 128, 80, 80]               0
    ​               Conv2d-80          [-1, 128, 80, 80]         147,456
    ​          BatchNorm2d-81          [-1, 128, 80, 80]             256
    ​                 SiLU-82          [-1, 128, 80, 80]               0
    ​                 Conv-83          [-1, 128, 80, 80]               0
    ​           Bottleneck-84          [-1, 128, 80, 80]               0
    ​               Conv2d-85          [-1, 128, 80, 80]          16,384
    ​          BatchNorm2d-86          [-1, 128, 80, 80]             256
    ​                 SiLU-87          [-1, 128, 80, 80]               0
    ​                 Conv-88          [-1, 128, 80, 80]               0
    ​               Conv2d-89          [-1, 128, 80, 80]         147,456
    ​          BatchNorm2d-90          [-1, 128, 80, 80]             256
    ​                 SiLU-91          [-1, 128, 80, 80]               0
    ​                 Conv-92          [-1, 128, 80, 80]               0
    ​           Bottleneck-93          [-1, 128, 80, 80]               0
    ​               Conv2d-94          [-1, 128, 80, 80]          16,384
    ​          BatchNorm2d-95          [-1, 128, 80, 80]             256
    ​                 SiLU-96          [-1, 128, 80, 80]               0
    ​                 Conv-97          [-1, 128, 80, 80]               0
    ​               Conv2d-98          [-1, 128, 80, 80]         147,456
    ​          BatchNorm2d-99          [-1, 128, 80, 80]             256
    ​                SiLU-100          [-1, 128, 80, 80]               0
    ​                Conv-101          [-1, 128, 80, 80]               0
    ​          Bottleneck-102          [-1, 128, 80, 80]               0
    ​              Conv2d-103          [-1, 128, 80, 80]          16,384
    ​         BatchNorm2d-104          [-1, 128, 80, 80]             256
    ​                SiLU-105          [-1, 128, 80, 80]               0
    ​                Conv-106          [-1, 128, 80, 80]               0
    ​              Conv2d-107          [-1, 128, 80, 80]         147,456
    ​         BatchNorm2d-108          [-1, 128, 80, 80]             256
    ​                SiLU-109          [-1, 128, 80, 80]               0
    ​                Conv-110          [-1, 128, 80, 80]               0
    ​          Bottleneck-111          [-1, 128, 80, 80]               0
    ​              Conv2d-112          [-1, 128, 80, 80]          16,384
    ​         BatchNorm2d-113          [-1, 128, 80, 80]             256
    ​                SiLU-114          [-1, 128, 80, 80]               0
    ​                Conv-115          [-1, 128, 80, 80]               0
    ​              Conv2d-116          [-1, 128, 80, 80]         147,456
    ​         BatchNorm2d-117          [-1, 128, 80, 80]             256
    ​                SiLU-118          [-1, 128, 80, 80]               0
    ​                Conv-119          [-1, 128, 80, 80]               0
    ​          Bottleneck-120          [-1, 128, 80, 80]               0
    ​              Conv2d-121          [-1, 128, 80, 80]          16,384
    ​         BatchNorm2d-122          [-1, 128, 80, 80]             256
    ​                SiLU-123          [-1, 128, 80, 80]               0
    ​                Conv-124          [-1, 128, 80, 80]               0
    ​              Conv2d-125          [-1, 128, 80, 80]         147,456
    ​         BatchNorm2d-126          [-1, 128, 80, 80]             256
    ​                SiLU-127          [-1, 128, 80, 80]               0
    ​                Conv-128          [-1, 128, 80, 80]               0
    ​          Bottleneck-129          [-1, 128, 80, 80]               0
    ​              Conv2d-130          [-1, 128, 80, 80]          16,384
    ​         BatchNorm2d-131          [-1, 128, 80, 80]             256
    ​                SiLU-132          [-1, 128, 80, 80]               0
    ​                Conv-133          [-1, 128, 80, 80]               0
    ​              Conv2d-134          [-1, 128, 80, 80]         147,456
    ​         BatchNorm2d-135          [-1, 128, 80, 80]             256
    ​                SiLU-136          [-1, 128, 80, 80]               0
    ​                Conv-137          [-1, 128, 80, 80]               0
    ​          Bottleneck-138          [-1, 128, 80, 80]               0
    ​              Conv2d-139          [-1, 128, 80, 80]          32,768
    ​         BatchNorm2d-140          [-1, 128, 80, 80]             256
    ​                SiLU-141          [-1, 128, 80, 80]               0
    ​                Conv-142          [-1, 128, 80, 80]               0
    ​              Conv2d-143          [-1, 256, 80, 80]          65,536
    ​         BatchNorm2d-144          [-1, 256, 80, 80]             512
    ​                SiLU-145          [-1, 256, 80, 80]               0
    ​                Conv-146          [-1, 256, 80, 80]               0
    ​                  C3-147          [-1, 256, 80, 80]               0
    ​              Conv2d-148          [-1, 512, 40, 40]       1,179,648
    ​         BatchNorm2d-149          [-1, 512, 40, 40]           1,024
    ​                SiLU-150          [-1, 512, 40, 40]               0
    ​                Conv-151          [-1, 512, 40, 40]               0
    ​              Conv2d-152          [-1, 256, 40, 40]         131,072
    ​         BatchNorm2d-153          [-1, 256, 40, 40]             512
    ​                SiLU-154          [-1, 256, 40, 40]               0
    ​                Conv-155          [-1, 256, 40, 40]               0
    ​              Conv2d-156          [-1, 256, 40, 40]          65,536
    ​         BatchNorm2d-157          [-1, 256, 40, 40]             512
    ​                SiLU-158          [-1, 256, 40, 40]               0
    ​                Conv-159          [-1, 256, 40, 40]               0
    ​              Conv2d-160          [-1, 256, 40, 40]         589,824
    ​         BatchNorm2d-161          [-1, 256, 40, 40]             512
    ​                SiLU-162          [-1, 256, 40, 40]               0
    ​                Conv-163          [-1, 256, 40, 40]               0
    ​          Bottleneck-164          [-1, 256, 40, 40]               0
    ​              Conv2d-165          [-1, 256, 40, 40]          65,536
    ​         BatchNorm2d-166          [-1, 256, 40, 40]             512
    ​                SiLU-167          [-1, 256, 40, 40]               0
    ​                Conv-168          [-1, 256, 40, 40]               0
    ​              Conv2d-169          [-1, 256, 40, 40]         589,824
    ​         BatchNorm2d-170          [-1, 256, 40, 40]             512
    ​                SiLU-171          [-1, 256, 40, 40]               0
    ​                Conv-172          [-1, 256, 40, 40]               0
    ​          Bottleneck-173          [-1, 256, 40, 40]               0
    ​              Conv2d-174          [-1, 256, 40, 40]          65,536
    ​         BatchNorm2d-175          [-1, 256, 40, 40]             512
    ​                SiLU-176          [-1, 256, 40, 40]               0
    ​                Conv-177          [-1, 256, 40, 40]               0
    ​              Conv2d-178          [-1, 256, 40, 40]         589,824
    ​         BatchNorm2d-179          [-1, 256, 40, 40]             512
    ​                SiLU-180          [-1, 256, 40, 40]               0
    ​                Conv-181          [-1, 256, 40, 40]               0
    ​          Bottleneck-182          [-1, 256, 40, 40]               0
    ​              Conv2d-183          [-1, 256, 40, 40]          65,536
    ​         BatchNorm2d-184          [-1, 256, 40, 40]             512
    ​                SiLU-185          [-1, 256, 40, 40]               0
    ​                Conv-186          [-1, 256, 40, 40]               0
    ​              Conv2d-187          [-1, 256, 40, 40]         589,824
    ​         BatchNorm2d-188          [-1, 256, 40, 40]             512
    ​                SiLU-189          [-1, 256, 40, 40]               0
    ​                Conv-190          [-1, 256, 40, 40]               0
    ​          Bottleneck-191          [-1, 256, 40, 40]               0
    ​              Conv2d-192          [-1, 256, 40, 40]          65,536
    ​         BatchNorm2d-193          [-1, 256, 40, 40]             512
    ​                SiLU-194          [-1, 256, 40, 40]               0
    ​                Conv-195          [-1, 256, 40, 40]               0
    ​              Conv2d-196          [-1, 256, 40, 40]         589,824
    ​         BatchNorm2d-197          [-1, 256, 40, 40]             512
    ​                SiLU-198          [-1, 256, 40, 40]               0
    ​                Conv-199          [-1, 256, 40, 40]               0
    ​          Bottleneck-200          [-1, 256, 40, 40]               0
    ​              Conv2d-201          [-1, 256, 40, 40]          65,536
    ​         BatchNorm2d-202          [-1, 256, 40, 40]             512
    ​                SiLU-203          [-1, 256, 40, 40]               0
    ​                Conv-204          [-1, 256, 40, 40]               0
    ​              Conv2d-205          [-1, 256, 40, 40]         589,824
    ​         BatchNorm2d-206          [-1, 256, 40, 40]             512
    ​                SiLU-207          [-1, 256, 40, 40]               0
    ​                Conv-208          [-1, 256, 40, 40]               0
    ​          Bottleneck-209          [-1, 256, 40, 40]               0
    ​              Conv2d-210          [-1, 256, 40, 40]          65,536
    ​         BatchNorm2d-211          [-1, 256, 40, 40]             512
    ​                SiLU-212          [-1, 256, 40, 40]               0
    ​                Conv-213          [-1, 256, 40, 40]               0
    ​              Conv2d-214          [-1, 256, 40, 40]         589,824
    ​         BatchNorm2d-215          [-1, 256, 40, 40]             512
    ​                SiLU-216          [-1, 256, 40, 40]               0
    ​                Conv-217          [-1, 256, 40, 40]               0
    ​          Bottleneck-218          [-1, 256, 40, 40]               0
    ​              Conv2d-219          [-1, 256, 40, 40]          65,536
    ​         BatchNorm2d-220          [-1, 256, 40, 40]             512
    ​                SiLU-221          [-1, 256, 40, 40]               0
    ​                Conv-222          [-1, 256, 40, 40]               0
    ​              Conv2d-223          [-1, 256, 40, 40]         589,824
    ​         BatchNorm2d-224          [-1, 256, 40, 40]             512
    ​                SiLU-225          [-1, 256, 40, 40]               0
    ​                Conv-226          [-1, 256, 40, 40]               0
    ​          Bottleneck-227          [-1, 256, 40, 40]               0
    ​              Conv2d-228          [-1, 256, 40, 40]          65,536
    ​         BatchNorm2d-229          [-1, 256, 40, 40]             512
    ​                SiLU-230          [-1, 256, 40, 40]               0
    ​                Conv-231          [-1, 256, 40, 40]               0
    ​              Conv2d-232          [-1, 256, 40, 40]         589,824
    ​         BatchNorm2d-233          [-1, 256, 40, 40]             512
    ​                SiLU-234          [-1, 256, 40, 40]               0
    ​                Conv-235          [-1, 256, 40, 40]               0
    ​          Bottleneck-236          [-1, 256, 40, 40]               0
    ​              Conv2d-237          [-1, 256, 40, 40]         131,072
    ​         BatchNorm2d-238          [-1, 256, 40, 40]             512
    ​                SiLU-239          [-1, 256, 40, 40]               0
    ​                Conv-240          [-1, 256, 40, 40]               0
    ​              Conv2d-241          [-1, 512, 40, 40]         262,144
    ​         BatchNorm2d-242          [-1, 512, 40, 40]           1,024
    ​                SiLU-243          [-1, 512, 40, 40]               0
    ​                Conv-244          [-1, 512, 40, 40]               0
    ​                  C3-245          [-1, 512, 40, 40]               0
    ​              Conv2d-246         [-1, 1024, 20, 20]       4,718,592
    ​         BatchNorm2d-247         [-1, 1024, 20, 20]           2,048
    ​                SiLU-248         [-1, 1024, 20, 20]               0
    ​                Conv-249         [-1, 1024, 20, 20]               0
    ​              Conv2d-250          [-1, 512, 20, 20]         524,288
    ​         BatchNorm2d-251          [-1, 512, 20, 20]           1,024
    ​                SiLU-252          [-1, 512, 20, 20]               0
    ​                Conv-253          [-1, 512, 20, 20]               0
    ​           MaxPool2d-254          [-1, 512, 20, 20]               0
    ​           MaxPool2d-255          [-1, 512, 20, 20]               0
    ​           MaxPool2d-256          [-1, 512, 20, 20]               0
    ​              Conv2d-257         [-1, 1024, 20, 20]       2,097,152
    ​         BatchNorm2d-258         [-1, 1024, 20, 20]           2,048
    ​                SiLU-259         [-1, 1024, 20, 20]               0
    ​                Conv-260         [-1, 1024, 20, 20]               0
    ​                 SPP-261         [-1, 1024, 20, 20]               0
    ​              Conv2d-262          [-1, 512, 20, 20]         524,288
    ​         BatchNorm2d-263          [-1, 512, 20, 20]           1,024
    ​                SiLU-264          [-1, 512, 20, 20]               0
    ​                Conv-265          [-1, 512, 20, 20]               0
    ​              Conv2d-266          [-1, 512, 20, 20]         262,144
    ​         BatchNorm2d-267          [-1, 512, 20, 20]           1,024
    ​                SiLU-268          [-1, 512, 20, 20]               0
    ​                Conv-269          [-1, 512, 20, 20]               0
    ​              Conv2d-270          [-1, 512, 20, 20]       2,359,296
    ​         BatchNorm2d-271          [-1, 512, 20, 20]           1,024
    ​                SiLU-272          [-1, 512, 20, 20]               0
    ​                Conv-273          [-1, 512, 20, 20]               0
    ​          Bottleneck-274          [-1, 512, 20, 20]               0
    ​              Conv2d-275          [-1, 512, 20, 20]         262,144
    ​         BatchNorm2d-276          [-1, 512, 20, 20]           1,024
    ​                SiLU-277          [-1, 512, 20, 20]               0
    ​                Conv-278          [-1, 512, 20, 20]               0
    ​              Conv2d-279          [-1, 512, 20, 20]       2,359,296
    ​         BatchNorm2d-280          [-1, 512, 20, 20]           1,024
    ​                SiLU-281          [-1, 512, 20, 20]               0
    ​                Conv-282          [-1, 512, 20, 20]               0
    ​          Bottleneck-283          [-1, 512, 20, 20]               0
    ​              Conv2d-284          [-1, 512, 20, 20]         262,144
    ​         BatchNorm2d-285          [-1, 512, 20, 20]           1,024
    ​                SiLU-286          [-1, 512, 20, 20]               0
    ​                Conv-287          [-1, 512, 20, 20]               0
    ​              Conv2d-288          [-1, 512, 20, 20]       2,359,296
    ​         BatchNorm2d-289          [-1, 512, 20, 20]           1,024
    ​                SiLU-290          [-1, 512, 20, 20]               0
    ​                Conv-291          [-1, 512, 20, 20]               0
    ​          Bottleneck-292          [-1, 512, 20, 20]               0
    ​              Conv2d-293          [-1, 512, 20, 20]         524,288
    ​         BatchNorm2d-294          [-1, 512, 20, 20]           1,024
    ​                SiLU-295          [-1, 512, 20, 20]               0
    ​                Conv-296          [-1, 512, 20, 20]               0
    ​              Conv2d-297         [-1, 1024, 20, 20]       1,048,576
    ​         BatchNorm2d-298         [-1, 1024, 20, 20]           2,048
    ​                SiLU-299         [-1, 1024, 20, 20]               0
    ​                Conv-300         [-1, 1024, 20, 20]               0
    ​                  C3-301         [-1, 1024, 20, 20]               0
    ​          CSPDarknet-302  [[-1, 256, 80, 80], [-1, 512, 40, 40], [-1, 1024, 20, 20]]               0
    ​              Conv2d-303          [-1, 512, 20, 20]         524,288
    ​         BatchNorm2d-304          [-1, 512, 20, 20]           1,024
    ​                SiLU-305          [-1, 512, 20, 20]               0
    ​                Conv-306          [-1, 512, 20, 20]               0
    ​            Upsample-307          [-1, 512, 40, 40]               0
    ​              Conv2d-308          [-1, 256, 40, 40]         262,144
    ​         BatchNorm2d-309          [-1, 256, 40, 40]             512
    ​                SiLU-310          [-1, 256, 40, 40]               0
    ​                Conv-311          [-1, 256, 40, 40]               0
    ​              Conv2d-312          [-1, 256, 40, 40]          65,536
    ​         BatchNorm2d-313          [-1, 256, 40, 40]             512
    ​                SiLU-314          [-1, 256, 40, 40]               0
    ​                Conv-315          [-1, 256, 40, 40]               0
    ​              Conv2d-316          [-1, 256, 40, 40]         589,824
    ​         BatchNorm2d-317          [-1, 256, 40, 40]             512
    ​                SiLU-318          [-1, 256, 40, 40]               0
    ​                Conv-319          [-1, 256, 40, 40]               0
    ​          Bottleneck-320          [-1, 256, 40, 40]               0
    ​              Conv2d-321          [-1, 256, 40, 40]          65,536
    ​         BatchNorm2d-322          [-1, 256, 40, 40]             512
    ​                SiLU-323          [-1, 256, 40, 40]               0
    ​                Conv-324          [-1, 256, 40, 40]               0
    ​              Conv2d-325          [-1, 256, 40, 40]         589,824
    ​         BatchNorm2d-326          [-1, 256, 40, 40]             512
    ​                SiLU-327          [-1, 256, 40, 40]               0
    ​                Conv-328          [-1, 256, 40, 40]               0
    ​          Bottleneck-329          [-1, 256, 40, 40]               0
    ​              Conv2d-330          [-1, 256, 40, 40]          65,536
    ​         BatchNorm2d-331          [-1, 256, 40, 40]             512
    ​                SiLU-332          [-1, 256, 40, 40]               0
    ​                Conv-333          [-1, 256, 40, 40]               0
    ​              Conv2d-334          [-1, 256, 40, 40]         589,824
    ​         BatchNorm2d-335          [-1, 256, 40, 40]             512
    ​                SiLU-336          [-1, 256, 40, 40]               0
    ​                Conv-337          [-1, 256, 40, 40]               0
    ​          Bottleneck-338          [-1, 256, 40, 40]               0
    ​              Conv2d-339          [-1, 256, 40, 40]         262,144
    ​         BatchNorm2d-340          [-1, 256, 40, 40]             512
    ​                SiLU-341          [-1, 256, 40, 40]               0
    ​                Conv-342          [-1, 256, 40, 40]               0
    ​              Conv2d-343          [-1, 512, 40, 40]         262,144
    ​         BatchNorm2d-344          [-1, 512, 40, 40]           1,024
    ​                SiLU-345          [-1, 512, 40, 40]               0
    ​                Conv-346          [-1, 512, 40, 40]               0
    ​                  C3-347          [-1, 512, 40, 40]               0
    ​              Conv2d-348          [-1, 256, 40, 40]         131,072
    ​         BatchNorm2d-349          [-1, 256, 40, 40]             512
    ​                SiLU-350          [-1, 256, 40, 40]               0
    ​                Conv-351          [-1, 256, 40, 40]               0
    ​            Upsample-352          [-1, 256, 80, 80]               0
    ​              Conv2d-353          [-1, 128, 80, 80]          65,536
    ​         BatchNorm2d-354          [-1, 128, 80, 80]             256
    ​                SiLU-355          [-1, 128, 80, 80]               0
    ​                Conv-356          [-1, 128, 80, 80]               0
    ​              Conv2d-357          [-1, 128, 80, 80]          16,384
    ​         BatchNorm2d-358          [-1, 128, 80, 80]             256
    ​                SiLU-359          [-1, 128, 80, 80]               0
    ​                Conv-360          [-1, 128, 80, 80]               0
    ​              Conv2d-361          [-1, 128, 80, 80]         147,456
    ​         BatchNorm2d-362          [-1, 128, 80, 80]             256
    ​                SiLU-363          [-1, 128, 80, 80]               0
    ​                Conv-364          [-1, 128, 80, 80]               0
    ​          Bottleneck-365          [-1, 128, 80, 80]               0
    ​              Conv2d-366          [-1, 128, 80, 80]          16,384
    ​         BatchNorm2d-367          [-1, 128, 80, 80]             256
    ​                SiLU-368          [-1, 128, 80, 80]               0
    ​                Conv-369          [-1, 128, 80, 80]               0
    ​              Conv2d-370          [-1, 128, 80, 80]         147,456
    ​         BatchNorm2d-371          [-1, 128, 80, 80]             256
    ​                SiLU-372          [-1, 128, 80, 80]               0
    ​                Conv-373          [-1, 128, 80, 80]               0
    ​          Bottleneck-374          [-1, 128, 80, 80]               0
    ​              Conv2d-375          [-1, 128, 80, 80]          16,384
    ​         BatchNorm2d-376          [-1, 128, 80, 80]             256
    ​                SiLU-377          [-1, 128, 80, 80]               0
    ​                Conv-378          [-1, 128, 80, 80]               0
    ​              Conv2d-379          [-1, 128, 80, 80]         147,456
    ​         BatchNorm2d-380          [-1, 128, 80, 80]             256
    ​                SiLU-381          [-1, 128, 80, 80]               0
    ​                Conv-382          [-1, 128, 80, 80]               0
    ​          Bottleneck-383          [-1, 128, 80, 80]               0
    ​              Conv2d-384          [-1, 128, 80, 80]          65,536
    ​         BatchNorm2d-385          [-1, 128, 80, 80]             256
    ​                SiLU-386          [-1, 128, 80, 80]               0
    ​                Conv-387          [-1, 128, 80, 80]               0
    ​              Conv2d-388          [-1, 256, 80, 80]          65,536
    ​         BatchNorm2d-389          [-1, 256, 80, 80]             512
    ​                SiLU-390          [-1, 256, 80, 80]               0
    ​                Conv-391          [-1, 256, 80, 80]               0
    ​                  C3-392          [-1, 256, 80, 80]               0
    ​              Conv2d-393          [-1, 256, 40, 40]         589,824
    ​         BatchNorm2d-394          [-1, 256, 40, 40]             512
    ​                SiLU-395          [-1, 256, 40, 40]               0
    ​                Conv-396          [-1, 256, 40, 40]               0
    ​              Conv2d-397          [-1, 256, 40, 40]         131,072
    ​         BatchNorm2d-398          [-1, 256, 40, 40]             512
    ​                SiLU-399          [-1, 256, 40, 40]               0
    ​                Conv-400          [-1, 256, 40, 40]               0
    ​              Conv2d-401          [-1, 256, 40, 40]          65,536
    ​         BatchNorm2d-402          [-1, 256, 40, 40]             512
    ​                SiLU-403          [-1, 256, 40, 40]               0
    ​                Conv-404          [-1, 256, 40, 40]               0
    ​              Conv2d-405          [-1, 256, 40, 40]         589,824
    ​         BatchNorm2d-406          [-1, 256, 40, 40]             512
    ​                SiLU-407          [-1, 256, 40, 40]               0
    ​                Conv-408          [-1, 256, 40, 40]               0
    ​          Bottleneck-409          [-1, 256, 40, 40]               0
    ​              Conv2d-410          [-1, 256, 40, 40]          65,536
    ​         BatchNorm2d-411          [-1, 256, 40, 40]             512
    ​                SiLU-412          [-1, 256, 40, 40]               0
    ​                Conv-413          [-1, 256, 40, 40]               0
    ​              Conv2d-414          [-1, 256, 40, 40]         589,824
    ​         BatchNorm2d-415          [-1, 256, 40, 40]             512
    ​                SiLU-416          [-1, 256, 40, 40]               0
    ​                Conv-417          [-1, 256, 40, 40]               0
    ​          Bottleneck-418          [-1, 256, 40, 40]               0
    ​              Conv2d-419          [-1, 256, 40, 40]          65,536
    ​         BatchNorm2d-420          [-1, 256, 40, 40]             512
    ​                SiLU-421          [-1, 256, 40, 40]               0
    ​                Conv-422          [-1, 256, 40, 40]               0
    ​              Conv2d-423          [-1, 256, 40, 40]         589,824
    ​         BatchNorm2d-424          [-1, 256, 40, 40]             512
    ​                SiLU-425          [-1, 256, 40, 40]               0
    ​                Conv-426          [-1, 256, 40, 40]               0
    ​          Bottleneck-427          [-1, 256, 40, 40]               0
    ​              Conv2d-428          [-1, 256, 40, 40]         131,072
    ​         BatchNorm2d-429          [-1, 256, 40, 40]             512
    ​                SiLU-430          [-1, 256, 40, 40]               0
    ​                Conv-431          [-1, 256, 40, 40]               0
    ​              Conv2d-432          [-1, 512, 40, 40]         262,144
    ​         BatchNorm2d-433          [-1, 512, 40, 40]           1,024
    ​                SiLU-434          [-1, 512, 40, 40]               0
    ​                Conv-435          [-1, 512, 40, 40]               0
    ​                  C3-436          [-1, 512, 40, 40]               0
    ​              Conv2d-437          [-1, 512, 20, 20]       2,359,296
    ​         BatchNorm2d-438          [-1, 512, 20, 20]           1,024
    ​                SiLU-439          [-1, 512, 20, 20]               0
    ​                Conv-440          [-1, 512, 20, 20]               0
    ​              Conv2d-441          [-1, 512, 20, 20]         524,288
    ​         BatchNorm2d-442          [-1, 512, 20, 20]           1,024
    ​                SiLU-443          [-1, 512, 20, 20]               0
    ​                Conv-444          [-1, 512, 20, 20]               0
    ​              Conv2d-445          [-1, 512, 20, 20]         262,144
    ​         BatchNorm2d-446          [-1, 512, 20, 20]           1,024
    ​                SiLU-447          [-1, 512, 20, 20]               0
    ​                Conv-448          [-1, 512, 20, 20]               0
    ​              Conv2d-449          [-1, 512, 20, 20]       2,359,296
    ​         BatchNorm2d-450          [-1, 512, 20, 20]           1,024
    ​                SiLU-451          [-1, 512, 20, 20]               0
    ​                Conv-452          [-1, 512, 20, 20]               0
    ​          Bottleneck-453          [-1, 512, 20, 20]               0
    ​              Conv2d-454          [-1, 512, 20, 20]         262,144
    ​         BatchNorm2d-455          [-1, 512, 20, 20]           1,024
    ​                SiLU-456          [-1, 512, 20, 20]               0
    ​                Conv-457          [-1, 512, 20, 20]               0
    ​              Conv2d-458          [-1, 512, 20, 20]       2,359,296
    ​         BatchNorm2d-459          [-1, 512, 20, 20]           1,024
    ​                SiLU-460          [-1, 512, 20, 20]               0
    ​                Conv-461          [-1, 512, 20, 20]               0
    ​          Bottleneck-462          [-1, 512, 20, 20]               0
    ​              Conv2d-463          [-1, 512, 20, 20]         262,144
    ​         BatchNorm2d-464          [-1, 512, 20, 20]           1,024
    ​                SiLU-465          [-1, 512, 20, 20]               0
    ​                Conv-466          [-1, 512, 20, 20]               0
    ​              Conv2d-467          [-1, 512, 20, 20]       2,359,296
    ​         BatchNorm2d-468          [-1, 512, 20, 20]           1,024
    ​                SiLU-469          [-1, 512, 20, 20]               0
    ​                Conv-470          [-1, 512, 20, 20]               0
    ​          Bottleneck-471          [-1, 512, 20, 20]               0
    ​              Conv2d-472          [-1, 512, 20, 20]         524,288
    ​         BatchNorm2d-473          [-1, 512, 20, 20]           1,024
    ​                SiLU-474          [-1, 512, 20, 20]               0
    ​                Conv-475          [-1, 512, 20, 20]               0
    ​              Conv2d-476         [-1, 1024, 20, 20]       1,048,576
    ​         BatchNorm2d-477         [-1, 1024, 20, 20]           2,048
    ​                SiLU-478         [-1, 1024, 20, 20]               0
    ​                Conv-479         [-1, 1024, 20, 20]               0
    ​                  C3-480         [-1, 1024, 20, 20]               0
    ​              Conv2d-481          [-1, 255, 80, 80]          65,535
    ​              Conv2d-482          [-1, 255, 40, 40]         130,815
    ​    
                   Conv2d-483          [-1, 255, 20, 20]         261,375
        ================================================================
    Total params: 47,056,765
    Trainable params: 47,056,765
    
    Non-trainable params: 0
    ----------------------------------------------------------------
    
    Input size (MB): 4.69
    Forward/backward pass size (MB): 2730.40
    Params size (MB): 179.51
    
    Estimated Total Size (MB): 2914.60
    ----------------------------------------------------------------
    
    torch.Size([1, 64, 320, 320])
    Total GFLOPS: 115.918G
    Total params: 47.057M

​    




（7月11日）

## dataset和dataloader

- dataset是用于读取、导入、划分数据集的，即，打包数据集
- dataloader是用于数据预处理，resize、suffer、数据增强等，得到可以直接导入网络的数据



## 损失函数

### 均方差损失函数

- 用于预测宽高合适，小编以为宽高是定值，主要是预测它们之间的差值，故倾向线性预测



### 交叉熵损失函数

- 中心坐标的预测，它具有那种偏移不确定性
- 预测框有无目标
- 物体的类别预测



### 预测框loss预测

- 一个好的预测，loss应该关注到重合面积，中心点的距离，长宽比，不重合面积



#### Loss_iou系列

- 1 - iou： 如果两个框没有相交，iou为0，不能反映两个框的预测，且没有梯度回传，且无法反映重合度的效果，单纯反应重合面积，不考虑形状，优点，对尺度不敏感
- 1 - Giou： 与iou相比Giou的关注点不一样，Giou不仅关注重叠区域还关注其他非重叠区域，且GIoU有对称区间，取值范围[-1,1]。在两者重合的时候取最大值1，在两者无交集且无限远的时候取最小值-1，因此GIoU是一个非常好的距离度量指标。
- ![image-20220711180220727](C:\Users\Happy\AppData\Roaming\Typora\typora-user-images\image-20220711180220727.png)-    Diou更考虑框的回归机制，中心点的距离以，重合率以及尺度都考虑进去，减少发散问题
- ![image-20220711180749734](C:\Users\Happy\AppData\Roaming\Typora\typora-user-images\image-20220711180749734.png)-  这个loss就关注到了重合率，中心距离、以及长宽比。



## training



### 加载与训练模型打印的指标

原up主得模型得检测指标，他是在已经训练好的权重下再训练优化的

![image-20220715154653042](C:\Users\Happy\AppData\Roaming\Typora\typora-user-images\image-20220715154653042.png)

![image-20220715154741450](C:\Users\Happy\AppData\Roaming\Typora\typora-user-images\image-20220715154741450.png)





### 本机训练一个epoch



![image-20220712161351259](C:\Users\Happy\AppData\Roaming\Typora\typora-user-images\image-20220712161351259.png)

开始的随机性很大，这个epoch的loss开始是2.7左右，训练完以后如上图所示，可以明显看到loss下降了，以为这个随机性很好，其实想多了，这里的val即test，两个一样，开始时，val_loss为7.3左右，val完以后变成7.1左右，肉眼可见的变化。不过还好，因为现在只是测试一下，也算是正常。但这是在有权值的基础之上训练的。

下面是改变epoch参数和batch_size后，再次开始训练，随机性的确很大，一下子loss就变成了4.2左右。

![image-20220712161611094](C:\Users\Happy\AppData\Roaming\Typora\typora-user-images\image-20220712161611094.png)

因为受训练时长的影响，所以我先配置服务器虚拟环境。





7月13-14日

后面小编不太会lunux环境，所以就先用本机跑跑第一次时，所有的指标几乎都是0，后面慢慢显示有map，很低。回去一看，居然是数据集图片和标签对不上，改好以后，又跑一遍，发现练map都没有，但是，导入up得已经训练好的模型loss下降就很明显，而我从0开始训练的结果如下,，我不好说了。

![image-20220715103316182](C:\Users\Happy\AppData\Roaming\Typora\typora-user-images\image-20220715103316182.png)

开始寻找原因。



7月15日

​	今天过来，开始检查数据集，因为数据集有差错，可能是因为当时网络原因没有完整的下载，数据集的数目对不上，又重新加载数据集，运行生成VOC格式的数据集，并完成数据集的划分。由于我的设备可能没有原主的好，他设置的迭代参数很大，我根据我的设备和他的解释修改了epoch和batch_size，以及使用混合精度来训练，但我修改完成以后，我发现，我的batch_size为8时，我的loss几乎没有变化，这很不对劲。

​	我就开始思考，因为原主的迭代次数和batch_size是居于一定的比例设置的，然后我就更改了batch_size的大小，果然，目前的训练，loss是变化的而且是呈下降的趋势在变化。

​	我在之前的训练中也遇到过类似的，那时虽然原主的batch_siae比较大，且原主的loss下降的趋势也很平滑，但是我修改batch_size后，虽然我的loss变化的幅度大，但他整体的下降趋势比原主的好，最后得到的准确率比原主的准确率高了0.1，分类展示的效果也很好，所以我觉得是一次投入的数据集相对较多，而且epoch的数值也比较大，数据呈现的概率趋势比较整齐，且loss的更新次数也相对减少，及对网络的调整也变少了，而我batch_size相对而言是比较少的，对网络的更新和调整次数相对较多，检测效果也会稍好。所以，loss本身的值并不重要，loss平不平滑代表loss的趋势稳不稳定而已，而他所呈现的总趋势才是网络性能的体现。当然这还是要看网络结构复杂度和数据集大小的，因为过于频繁调整，网络过度敏感就不好了。故我也会用batch_size做一个小小的消融实验的。

![image-20220715201851986](C:\Users\Happy\AppData\Roaming\Typora\typora-user-images\image-20220715201851986.png)

虽然目前得到的map看起来不正常，但是，相比于第一次，她至少有数据了。



7月16日

今天de了一天的bug，查看代码。昨天出现的评测指标异常问题的原因还是数据集的问题，标签移动没有移完全，数据没加载完。不出意外，现在开始训练的应该是没有问题的，数据、标签，train、val都是对应的了。

代码能运行，评测指标异常，先查看数据集有没有问题，图片标签对应没有，数据有没有缺少等，然后再去查看代码，debug这些。



GitHub 上的网络结构示意图

[[![img](https://github.com/yuanxiao7/summer_project/raw/master/.%5Cpicture%5C8.png)](https://github.com/yuanxiao7/summer_project/blob/master/picture\8.png)](https://github.com/yuanxiao7/summer_project/commit/3cfd44dccc2e92a4887bd738cc83b5a2564d9202)f719d01d29830a4f005ad0a171c05bf5b8bffde0



7月17日



![image-20220717220948416](C:\Users\Happy\AppData\Roaming\Typora\typora-user-images\image-20220717220948416.png)



### 完整的100个epoch训练

7月19日

虽然一开始训练的指标看起来有问题，但是，我并没有停止训练，然后训着训着，指标就开始正常了，后面想想，刚开始从零训练的模型，指标不正常才是正常的。

我这一次训练，训练集17416，测试集1936，训了2天左右，配置如下

```
initialize network with normal type
Configurations:
----------------------------------------------------------------------
|                     keys |                                   values|
----------------------------------------------------------------------
|             classes_path |               model_data/voc_classes.txt|
|             anchors_path |              model_data/yolo_anchors.txt|
|             anchors_mask |        [[6, 7, 8], [3, 4, 5], [0, 1, 2]]|
|               model_path |                                         |
|              input_shape |                               [640, 640]|
|               Init_Epoch |                                        0|
|             Freeze_Epoch |                                       10|
|           UnFreeze_Epoch |                                      100|
|        Freeze_batch_size |                                        8|
|      Unfreeze_batch_size |                                       12|
|             Freeze_Train |                                    False|
|                  Init_lr |                                    0.001|
|                   Min_lr |                                    1e-05|
|           optimizer_type |                                     adam|
|                 momentum |                                    0.937|
|            lr_decay_type |                                      cos|
|              save_period |                                       10|
|                 save_dir |                                     logs|
|              num_workers |                                        0|
|                num_train |                                    17416|
|                  num_val |                                     1936|
----------------------------------------------------------------------
```



第一次迭代的结果是Total Loss: 2.378 || Val Loss: 1.275 ，第二次迭代的结果Total Loss: 0.605 || Val Loss: 0.291 ，loss下降得非常明显，我每10次迭代记录一下测试集的指标。

### 每隔10次迭代打印情况如下

1. ```
   Calculate Map.
   45.59% = aeroplane AP 	||	score_threhold=0.5 : F1=0.18 ; Recall=9.79% ; Precision=87.50%
   42.78% = bicycle AP 	||	score_threhold=0.5 : F1=0.14 ; Recall=7.63% ; Precision=100.00%
   16.78% = bird AP 	||	score_threhold=0.5 : F1=0.01 ; Recall=0.60% ; Precision=100.00%
   17.16% = boat AP 	||	score_threhold=0.5 : F1=0.01 ; Recall=0.75% ; Precision=100.00%
   3.39% = bottle AP 	||	score_threhold=0.5 : F1=0.00 ; Recall=0.00% ; Precision=0.00%
   55.35% = bus AP 	||	score_threhold=0.5 : F1=0.28 ; Recall=16.35% ; Precision=100.00%
   62.80% = car AP 	||	score_threhold=0.5 : F1=0.46 ; Recall=30.51% ; Precision=90.00%
   30.42% = cat AP 	||	score_threhold=0.5 : F1=0.01 ; Recall=0.67% ; Precision=100.00%
   23.11% = chair AP 	||	score_threhold=0.5 : F1=0.00 ; Recall=0.25% ; Precision=100.00%
   20.19% = cow AP 	||	score_threhold=0.5 : F1=0.02 ; Recall=0.90% ; Precision=100.00%
   6.97% = diningtable AP 	||	score_threhold=0.5 : F1=0.00 ; Recall=0.00% ; Precision=0.00%
   19.48% = dog AP 	||	score_threhold=0.5 : F1=0.01 ; Recall=0.44% ; Precision=100.00%
   40.61% = horse AP 	||	score_threhold=0.5 : F1=0.04 ; Recall=2.27% ; Precision=100.00%
   38.50% = motorbike AP 	||	score_threhold=0.5 : F1=0.02 ; Recall=0.90% ; Precision=100.00%
   62.90% = person AP 	||	score_threhold=0.5 : F1=0.42 ; Recall=27.17% ; Precision=92.28%
   5.57% = pottedplant AP 	||	score_threhold=0.5 : F1=0.01 ; Recall=0.58% ; Precision=100.00%
   35.94% = sheep AP 	||	score_threhold=0.5 : F1=0.08 ; Recall=4.44% ; Precision=57.14%
   10.78% = sofa AP 	||	score_threhold=0.5 : F1=0.02 ; Recall=1.03% ; Precision=100.00%
   45.06% = train AP 	||	score_threhold=0.5 : F1=0.06 ; Recall=2.86% ; Precision=75.00%
   37.47% = tvmonitor AP 	||	score_threhold=0.5 : F1=0.34 ; Recall=21.77% ; Precision=81.82%
   mAP = 31.04%
   Get map done.
   Epoch:10/100
   Total Loss: 0.144 || Val Loss: 0.092 
   Save best model to best_epoch_weights.pth
   ```

2. ```
   Calculate Map.
   55.90% = aeroplane AP 	||	score_threhold=0.5 : F1=0.30 ; Recall=18.18% ; Precision=92.86%
   56.28% = bicycle AP 	||	score_threhold=0.5 : F1=0.39 ; Recall=24.58% ; Precision=96.67%
   35.26% = bird AP 	||	score_threhold=0.5 : F1=0.15 ; Recall=8.38% ; Precision=100.00%
   30.80% = boat AP 	||	score_threhold=0.5 : F1=0.10 ; Recall=5.26% ; Precision=100.00%
   20.29% = bottle AP 	||	score_threhold=0.5 : F1=0.01 ; Recall=0.48% ; Precision=100.00%
   67.76% = bus AP 	||	score_threhold=0.5 : F1=0.50 ; Recall=33.65% ; Precision=94.59%
   69.09% = car AP 	||	score_threhold=0.5 : F1=0.59 ; Recall=43.83% ; Precision=90.50%
   46.41% = cat AP 	||	score_threhold=0.5 : F1=0.01 ; Recall=0.67% ; Precision=50.00%
   33.59% = chair AP 	||	score_threhold=0.5 : F1=0.10 ; Recall=5.21% ; Precision=84.00%
   22.33% = cow AP 	||	score_threhold=0.5 : F1=0.00 ; Recall=0.00% ; Precision=0.00%
   24.94% = diningtable AP 	||	score_threhold=0.5 : F1=0.02 ; Recall=0.99% ; Precision=100.00%
   32.18% = dog AP 	||	score_threhold=0.5 : F1=0.01 ; Recall=0.44% ; Precision=100.00%
   51.25% = horse AP 	||	score_threhold=0.5 : F1=0.29 ; Recall=16.67% ; Precision=100.00%
   51.10% = motorbike AP 	||	score_threhold=0.5 : F1=0.18 ; Recall=9.91% ; Precision=91.67%
   69.54% = person AP 	||	score_threhold=0.5 : F1=0.51 ; Recall=35.04% ; Precision=92.32%
   15.74% = pottedplant AP 	||	score_threhold=0.5 : F1=0.01 ; Recall=0.58% ; Precision=100.00%
   49.91% = sheep AP 	||	score_threhold=0.5 : F1=0.50 ; Recall=37.78% ; Precision=72.34%
   23.78% = sofa AP 	||	score_threhold=0.5 : F1=0.02 ; Recall=1.03% ; Precision=100.00%
   64.65% = train AP 	||	score_threhold=0.5 : F1=0.27 ; Recall=16.19% ; Precision=89.47%
   50.20% = tvmonitor AP 	||	score_threhold=0.5 : F1=0.45 ; Recall=30.65% ; Precision=86.36%
   mAP = 43.55%
   Get map done.
   Epoch:20/100
   Total Loss: 0.125 || Val Loss: 0.080 
   Save best model to best_epoch_weights.pth
   ```

   



3. ```
   Calculate Map.
   68.59% = aeroplane AP 	||	score_threhold=0.5 : F1=0.47 ; Recall=30.77% ; Precision=97.78%
   62.81% = bicycle AP 	||	score_threhold=0.5 : F1=0.51 ; Recall=34.75% ; Precision=93.18%
   50.98% = bird AP 	||	score_threhold=0.5 : F1=0.30 ; Recall=17.96% ; Precision=100.00%
   37.55% = boat AP 	||	score_threhold=0.5 : F1=0.30 ; Recall=18.05% ; Precision=92.31%
   33.56% = bottle AP 	||	score_threhold=0.5 : F1=0.16 ; Recall=8.70% ; Precision=94.74%
   73.74% = bus AP 	||	score_threhold=0.5 : F1=0.65 ; Recall=49.04% ; Precision=94.44%
   72.39% = car AP 	||	score_threhold=0.5 : F1=0.66 ; Recall=52.78% ; Precision=89.71%
   58.90% = cat AP 	||	score_threhold=0.5 : F1=0.05 ; Recall=2.68% ; Precision=80.00%
   44.02% = chair AP 	||	score_threhold=0.5 : F1=0.27 ; Recall=16.13% ; Precision=92.86%
   38.82% = cow AP 	||	score_threhold=0.5 : F1=0.05 ; Recall=2.70% ; Precision=60.00%
   39.54% = diningtable AP 	||	score_threhold=0.5 : F1=0.09 ; Recall=4.95% ; Precision=100.00%
   44.20% = dog AP 	||	score_threhold=0.5 : F1=0.05 ; Recall=2.62% ; Precision=85.71%
   54.30% = horse AP 	||	score_threhold=0.5 : F1=0.38 ; Recall=24.24% ; Precision=91.43%
   59.55% = motorbike AP 	||	score_threhold=0.5 : F1=0.31 ; Recall=18.92% ; Precision=87.50%
   73.27% = person AP 	||	score_threhold=0.5 : F1=0.58 ; Recall=42.74% ; Precision=91.85%
   27.32% = pottedplant AP 	||	score_threhold=0.5 : F1=0.12 ; Recall=6.43% ; Precision=68.75%
   57.44% = sheep AP 	||	score_threhold=0.5 : F1=0.56 ; Recall=47.78% ; Precision=68.25%
   28.76% = sofa AP 	||	score_threhold=0.5 : F1=0.12 ; Recall=6.19% ; Precision=85.71%
   69.38% = train AP 	||	score_threhold=0.5 : F1=0.42 ; Recall=27.62% ; Precision=85.29%
   58.38% = tvmonitor AP 	||	score_threhold=0.5 : F1=0.50 ; Recall=36.29% ; Precision=81.82%
   mAP = 52.67%
   Get map done.
   Epoch:30/100
   Total Loss: 0.116 || Val Loss: 0.071 
   Save best model to best_epoch_weights.pth
   ```

   



4. ```
   Calculate Map.
   74.75% = aeroplane AP 	||	score_threhold=0.5 : F1=0.54 ; Recall=38.46% ; Precision=93.22%
   66.07% = bicycle AP 	||	score_threhold=0.5 : F1=0.62 ; Recall=47.46% ; Precision=87.50%
   61.48% = bird AP 	||	score_threhold=0.5 : F1=0.43 ; Recall=27.54% ; Precision=97.87%
   46.41% = boat AP 	||	score_threhold=0.5 : F1=0.38 ; Recall=24.81% ; Precision=84.62%
   44.24% = bottle AP 	||	score_threhold=0.5 : F1=0.33 ; Recall=20.29% ; Precision=85.71%
   77.15% = bus AP 	||	score_threhold=0.5 : F1=0.70 ; Recall=57.69% ; Precision=89.55%
   75.12% = car AP 	||	score_threhold=0.5 : F1=0.74 ; Recall=62.23% ; Precision=89.86%
   66.40% = cat AP 	||	score_threhold=0.5 : F1=0.26 ; Recall=15.44% ; Precision=88.46%
   47.70% = chair AP 	||	score_threhold=0.5 : F1=0.42 ; Recall=27.54% ; Precision=88.10%
   49.65% = cow AP 	||	score_threhold=0.5 : F1=0.35 ; Recall=23.42% ; Precision=70.27%
   46.86% = diningtable AP 	||	score_threhold=0.5 : F1=0.20 ; Recall=10.89% ; Precision=100.00%
   53.79% = dog AP 	||	score_threhold=0.5 : F1=0.19 ; Recall=10.92% ; Precision=89.29%
   62.66% = horse AP 	||	score_threhold=0.5 : F1=0.51 ; Recall=34.85% ; Precision=93.88%
   66.20% = motorbike AP 	||	score_threhold=0.5 : F1=0.46 ; Recall=30.63% ; Precision=91.89%
   76.38% = person AP 	||	score_threhold=0.5 : F1=0.65 ; Recall=50.96% ; Precision=90.10%
   35.17% = pottedplant AP 	||	score_threhold=0.5 : F1=0.24 ; Recall=14.04% ; Precision=72.73%
   67.68% = sheep AP 	||	score_threhold=0.5 : F1=0.68 ; Recall=61.11% ; Precision=76.39%
   33.61% = sofa AP 	||	score_threhold=0.5 : F1=0.21 ; Recall=12.37% ; Precision=75.00%
   73.38% = train AP 	||	score_threhold=0.5 : F1=0.64 ; Recall=48.57% ; Precision=92.73%
   62.86% = tvmonitor AP 	||	score_threhold=0.5 : F1=0.59 ; Recall=46.77% ; Precision=81.69%
   mAP = 59.38%
   Get map done.
   Epoch:40/100
   Total Loss: 0.109 || Val Loss: 0.066 
   Save best model to best_epoch_weights.pth
   ```

   



5. ```
   Calculate Map.
   77.67% = aeroplane AP 	||	score_threhold=0.5 : F1=0.64 ; Recall=48.25% ; Precision=95.83%
   69.55% = bicycle AP 	||	score_threhold=0.5 : F1=0.68 ; Recall=54.24% ; Precision=90.14%
   64.81% = bird AP 	||	score_threhold=0.5 : F1=0.50 ; Recall=34.13% ; Precision=91.94%
   50.77% = boat AP 	||	score_threhold=0.5 : F1=0.45 ; Recall=30.08% ; Precision=86.96%
   49.17% = bottle AP 	||	score_threhold=0.5 : F1=0.42 ; Recall=28.50% ; Precision=79.73%
   79.67% = bus AP 	||	score_threhold=0.5 : F1=0.73 ; Recall=62.50% ; Precision=89.04%
   77.06% = car AP 	||	score_threhold=0.5 : F1=0.75 ; Recall=64.89% ; Precision=87.87%
   68.79% = cat AP 	||	score_threhold=0.5 : F1=0.38 ; Recall=24.16% ; Precision=90.00%
   49.84% = chair AP 	||	score_threhold=0.5 : F1=0.46 ; Recall=31.27% ; Precision=85.71%
   55.35% = cow AP 	||	score_threhold=0.5 : F1=0.46 ; Recall=33.33% ; Precision=75.51%
   49.00% = diningtable AP 	||	score_threhold=0.5 : F1=0.32 ; Recall=18.81% ; Precision=100.00%
   61.87% = dog AP 	||	score_threhold=0.5 : F1=0.32 ; Recall=19.65% ; Precision=84.91%
   63.47% = horse AP 	||	score_threhold=0.5 : F1=0.54 ; Recall=38.64% ; Precision=89.47%
   64.88% = motorbike AP 	||	score_threhold=0.5 : F1=0.51 ; Recall=35.14% ; Precision=90.70%
   77.76% = person AP 	||	score_threhold=0.5 : F1=0.68 ; Recall=55.34% ; Precision=89.36%
   41.13% = pottedplant AP 	||	score_threhold=0.5 : F1=0.32 ; Recall=19.88% ; Precision=79.07%
   73.14% = sheep AP 	||	score_threhold=0.5 : F1=0.72 ; Recall=66.67% ; Precision=77.92%
   37.82% = sofa AP 	||	score_threhold=0.5 : F1=0.35 ; Recall=22.68% ; Precision=81.48%
   75.19% = train AP 	||	score_threhold=0.5 : F1=0.70 ; Recall=57.14% ; Precision=90.91%
   65.53% = tvmonitor AP 	||	score_threhold=0.5 : F1=0.64 ; Recall=54.03% ; Precision=79.76%
   mAP = 62.62%
   Get map done.
   Epoch:50/100
   Total Loss: 0.104 || Val Loss: 0.063 
   Save best model to best_epoch_weights.pth
   ```

   

#### 收敛趋势

- 在第五次打印时，验证集的loss趋于稳定，而训练集的loss在很缓慢的下降，而此时的map已经达到60几了。



6. ```
   Calculate Map.
   78.17% = aeroplane AP 	||	score_threhold=0.5 : F1=0.68 ; Recall=53.15% ; Precision=95.00%
   70.53% = bicycle AP 	||	score_threhold=0.5 : F1=0.67 ; Recall=53.39% ; Precision=90.00%
   68.33% = bird AP 	||	score_threhold=0.5 : F1=0.57 ; Recall=41.32% ; Precision=90.79%
   54.20% = boat AP 	||	score_threhold=0.5 : F1=0.45 ; Recall=30.08% ; Precision=86.96%
   50.46% = bottle AP 	||	score_threhold=0.5 : F1=0.49 ; Recall=34.78% ; Precision=83.72%
   82.06% = bus AP 	||	score_threhold=0.5 : F1=0.77 ; Recall=67.31% ; Precision=89.74%
   79.01% = car AP 	||	score_threhold=0.5 : F1=0.76 ; Recall=66.83% ; Precision=87.34%
   70.07% = cat AP 	||	score_threhold=0.5 : F1=0.43 ; Recall=28.86% ; Precision=87.76%
   50.40% = chair AP 	||	score_threhold=0.5 : F1=0.47 ; Recall=33.00% ; Precision=82.61%
   57.24% = cow AP 	||	score_threhold=0.5 : F1=0.58 ; Recall=45.95% ; Precision=77.27%
   53.21% = diningtable AP 	||	score_threhold=0.5 : F1=0.38 ; Recall=23.76% ; Precision=96.00%
   63.35% = dog AP 	||	score_threhold=0.5 : F1=0.41 ; Recall=26.64% ; Precision=88.41%
   64.77% = horse AP 	||	score_threhold=0.5 : F1=0.58 ; Recall=43.18% ; Precision=89.06%
   68.30% = motorbike AP 	||	score_threhold=0.5 : F1=0.59 ; Recall=44.14% ; Precision=89.09%
   79.01% = person AP 	||	score_threhold=0.5 : F1=0.70 ; Recall=57.73% ; Precision=89.43%
   44.36% = pottedplant AP 	||	score_threhold=0.5 : F1=0.38 ; Recall=24.56% ; Precision=82.35%
   73.62% = sheep AP 	||	score_threhold=0.5 : F1=0.71 ; Recall=67.78% ; Precision=75.31%
   38.63% = sofa AP 	||	score_threhold=0.5 : F1=0.38 ; Recall=24.74% ; Precision=80.00%
   74.42% = train AP 	||	score_threhold=0.5 : F1=0.73 ; Recall=59.05% ; Precision=93.94%
   68.67% = tvmonitor AP 	||	score_threhold=0.5 : F1=0.67 ; Recall=57.26% ; Precision=79.78%
   mAP = 64.44%
   Get map done.
   Epoch:60/100
   Total Loss: 0.100 || Val Loss: 0.062 
   ```

   



7. ```
   Calculate Map.
   78.80% = aeroplane AP 	||	score_threhold=0.5 : F1=0.68 ; Recall=53.85% ; Precision=92.77%
   71.32% = bicycle AP 	||	score_threhold=0.5 : F1=0.70 ; Recall=56.78% ; Precision=90.54%
   68.27% = bird AP 	||	score_threhold=0.5 : F1=0.58 ; Recall=43.11% ; Precision=90.00%
   55.41% = boat AP 	||	score_threhold=0.5 : F1=0.49 ; Recall=34.59% ; Precision=86.79%
   52.32% = bottle AP 	||	score_threhold=0.5 : F1=0.53 ; Recall=39.13% ; Precision=81.00%
   82.20% = bus AP 	||	score_threhold=0.5 : F1=0.78 ; Recall=70.19% ; Precision=87.95%
   79.55% = car AP 	||	score_threhold=0.5 : F1=0.78 ; Recall=69.01% ; Precision=88.79%
   70.97% = cat AP 	||	score_threhold=0.5 : F1=0.47 ; Recall=32.21% ; Precision=87.27%
   50.98% = chair AP 	||	score_threhold=0.5 : F1=0.48 ; Recall=34.49% ; Precision=80.81%
   59.21% = cow AP 	||	score_threhold=0.5 : F1=0.57 ; Recall=46.85% ; Precision=74.29%
   55.12% = diningtable AP 	||	score_threhold=0.5 : F1=0.37 ; Recall=22.77% ; Precision=95.83%
   65.48% = dog AP 	||	score_threhold=0.5 : F1=0.45 ; Recall=30.57% ; Precision=86.42%
   69.05% = horse AP 	||	score_threhold=0.5 : F1=0.62 ; Recall=46.97% ; Precision=91.18%
   67.61% = motorbike AP 	||	score_threhold=0.5 : F1=0.60 ; Recall=46.85% ; Precision=83.87%
   79.08% = person AP 	||	score_threhold=0.5 : F1=0.72 ; Recall=59.88% ; Precision=89.23%
   45.45% = pottedplant AP 	||	score_threhold=0.5 : F1=0.41 ; Recall=26.90% ; Precision=83.64%
   75.31% = sheep AP 	||	score_threhold=0.5 : F1=0.73 ; Recall=71.11% ; Precision=74.42%
   40.11% = sofa AP 	||	score_threhold=0.5 : F1=0.41 ; Recall=28.87% ; Precision=71.79%
   72.84% = train AP 	||	score_threhold=0.5 : F1=0.70 ; Recall=57.14% ; Precision=90.91%
   69.65% = tvmonitor AP 	||	score_threhold=0.5 : F1=0.69 ; Recall=58.06% ; Precision=83.72%
   mAP = 65.44%
   Get map done.
   Epoch:70/100
   Total Loss: 0.097 || Val Loss: 0.061 
   Save best model to best_epoch_weights.pth
   
   ```

#### loss的变化情况

从这里验证loss几乎不变了

测试集loss突然骤降是因为在总epoch的0.7以后关闭mosaic数据增强。

8. ```
   Calculate Map.
   81.96% = aeroplane AP 	||	score_threhold=0.5 : F1=0.71 ; Recall=57.34% ; Precision=93.18%
   73.18% = bicycle AP 	||	score_threhold=0.5 : F1=0.71 ; Recall=58.47% ; Precision=89.61%
   69.08% = bird AP 	||	score_threhold=0.5 : F1=0.58 ; Recall=43.71% ; Precision=85.88%
   54.26% = boat AP 	||	score_threhold=0.5 : F1=0.50 ; Recall=35.34% ; Precision=87.04%
   54.06% = bottle AP 	||	score_threhold=0.5 : F1=0.54 ; Recall=40.10% ; Precision=83.00%
   81.08% = bus AP 	||	score_threhold=0.5 : F1=0.80 ; Recall=73.08% ; Precision=89.41%
   79.57% = car AP 	||	score_threhold=0.5 : F1=0.78 ; Recall=68.77% ; Precision=90.73%
   73.25% = cat AP 	||	score_threhold=0.5 : F1=0.53 ; Recall=37.58% ; Precision=87.50%
   52.64% = chair AP 	||	score_threhold=0.5 : F1=0.49 ; Recall=35.24% ; Precision=81.61%
   57.71% = cow AP 	||	score_threhold=0.5 : F1=0.60 ; Recall=49.55% ; Precision=77.46%
   54.22% = diningtable AP 	||	score_threhold=0.5 : F1=0.39 ; Recall=24.75% ; Precision=96.15%
   67.19% = dog AP 	||	score_threhold=0.5 : F1=0.50 ; Recall=34.93% ; Precision=86.96%
   69.28% = horse AP 	||	score_threhold=0.5 : F1=0.64 ; Recall=50.76% ; Precision=88.16%
   68.75% = motorbike AP 	||	score_threhold=0.5 : F1=0.63 ; Recall=49.55% ; Precision=87.30%
   80.47% = person AP 	||	score_threhold=0.5 : F1=0.73 ; Recall=60.87% ; Precision=90.62%
   44.81% = pottedplant AP 	||	score_threhold=0.5 : F1=0.39 ; Recall=26.32% ; Precision=77.59%
   76.51% = sheep AP 	||	score_threhold=0.5 : F1=0.73 ; Recall=72.22% ; Precision=73.86%
   40.92% = sofa AP 	||	score_threhold=0.5 : F1=0.43 ; Recall=29.90% ; Precision=76.32%
   77.40% = train AP 	||	score_threhold=0.5 : F1=0.71 ; Recall=58.10% ; Precision=92.42%
   70.35% = tvmonitor AP 	||	score_threhold=0.5 : F1=0.69 ; Recall=58.06% ; Precision=84.71%
   mAP = 66.33%
   Get map done.
   Epoch:80/100
   Total Loss: 0.060 || Val Loss: 0.061 
   
   ```

   



9. ```
   Calculate Map.
   82.19% = aeroplane AP 	||	score_threhold=0.5 : F1=0.69 ; Recall=55.24% ; Precision=92.94%
   72.30% = bicycle AP 	||	score_threhold=0.5 : F1=0.69 ; Recall=56.78% ; Precision=89.33%
   69.72% = bird AP 	||	score_threhold=0.5 : F1=0.58 ; Recall=44.31% ; Precision=84.09%
   56.05% = boat AP 	||	score_threhold=0.5 : F1=0.51 ; Recall=36.09% ; Precision=88.89%
   54.48% = bottle AP 	||	score_threhold=0.5 : F1=0.55 ; Recall=41.55% ; Precision=82.69%
   80.97% = bus AP 	||	score_threhold=0.5 : F1=0.79 ; Recall=72.12% ; Precision=88.24%
   78.85% = car AP 	||	score_threhold=0.5 : F1=0.77 ; Recall=67.80% ; Precision=90.03%
   72.29% = cat AP 	||	score_threhold=0.5 : F1=0.57 ; Recall=42.28% ; Precision=85.14%
   53.45% = chair AP 	||	score_threhold=0.5 : F1=0.51 ; Recall=36.72% ; Precision=82.22%
   59.58% = cow AP 	||	score_threhold=0.5 : F1=0.62 ; Recall=51.35% ; Precision=78.08%
   54.29% = diningtable AP 	||	score_threhold=0.5 : F1=0.39 ; Recall=24.75% ; Precision=89.29%
   67.61% = dog AP 	||	score_threhold=0.5 : F1=0.55 ; Recall=40.17% ; Precision=88.46%
   70.93% = horse AP 	||	score_threhold=0.5 : F1=0.66 ; Recall=52.27% ; Precision=89.61%
   68.99% = motorbike AP 	||	score_threhold=0.5 : F1=0.64 ; Recall=51.35% ; Precision=86.36%
   81.07% = person AP 	||	score_threhold=0.5 : F1=0.73 ; Recall=61.40% ; Precision=91.33%
   45.46% = pottedplant AP 	||	score_threhold=0.5 : F1=0.41 ; Recall=27.49% ; Precision=78.33%
   77.97% = sheep AP 	||	score_threhold=0.5 : F1=0.74 ; Recall=74.44% ; Precision=72.83%
   42.76% = sofa AP 	||	score_threhold=0.5 : F1=0.43 ; Recall=29.90% ; Precision=76.32%
   78.58% = train AP 	||	score_threhold=0.5 : F1=0.73 ; Recall=59.05% ; Precision=93.94%
   70.78% = tvmonitor AP 	||	score_threhold=0.5 : F1=0.70 ; Recall=58.06% ; Precision=86.75%
   mAP = 66.92%
   Get map done.
   Epoch:90/100
   Total Loss: 0.059 || Val Loss: 0.061 
   
   ```

   

#### 训练结束

10. ```
    Calculate Map.
    82.31% = aeroplane AP 	||	score_threhold=0.5 : F1=0.72 ; Recall=58.04% ; Precision=94.32%
    73.86% = bicycle AP 	||	score_threhold=0.5 : F1=0.71 ; Recall=58.47% ; Precision=89.61%
    71.09% = bird AP 	||	score_threhold=0.5 : F1=0.60 ; Recall=46.11% ; Precision=85.56%
    56.64% = boat AP 	||	score_threhold=0.5 : F1=0.51 ; Recall=36.09% ; Precision=88.89%
    55.22% = bottle AP 	||	score_threhold=0.5 : F1=0.55 ; Recall=41.55% ; Precision=83.50%
    81.02% = bus AP 	||	score_threhold=0.5 : F1=0.79 ; Recall=72.12% ; Precision=88.24%
    79.78% = car AP 	||	score_threhold=0.5 : F1=0.78 ; Recall=68.04% ; Precision=90.06%
    72.35% = cat AP 	||	score_threhold=0.5 : F1=0.57 ; Recall=42.95% ; Precision=86.49%
    53.84% = chair AP 	||	score_threhold=0.5 : F1=0.51 ; Recall=37.22% ; Precision=81.52%
    59.78% = cow AP 	||	score_threhold=0.5 : F1=0.62 ; Recall=51.35% ; Precision=77.03%
    54.84% = diningtable AP 	||	score_threhold=0.5 : F1=0.40 ; Recall=25.74% ; Precision=89.66%
    67.63% = dog AP 	||	score_threhold=0.5 : F1=0.57 ; Recall=41.92% ; Precision=88.89%
    69.88% = horse AP 	||	score_threhold=0.5 : F1=0.66 ; Recall=52.27% ; Precision=89.61%
    69.37% = motorbike AP 	||	score_threhold=0.5 : F1=0.64 ; Recall=51.35% ; Precision=86.36%
    80.86% = person AP 	||	score_threhold=0.5 : F1=0.73 ; Recall=61.22% ; Precision=91.15%
    45.85% = pottedplant AP 	||	score_threhold=0.5 : F1=0.41 ; Recall=27.49% ; Precision=79.66%
    78.74% = sheep AP 	||	score_threhold=0.5 : F1=0.75 ; Recall=76.67% ; Precision=74.19%
    43.23% = sofa AP 	||	score_threhold=0.5 : F1=0.44 ; Recall=30.93% ; Precision=76.92%
    78.73% = train AP 	||	score_threhold=0.5 : F1=0.73 ; Recall=60.00% ; Precision=92.65%
    71.54% = tvmonitor AP 	||	score_threhold=0.5 : F1=0.69 ; Recall=58.06% ; Precision=85.71%
    mAP = 67.33%
    Get map done.
    Epoch:100/100
    Total Loss: 0.058 || Val Loss: 0.061 
    
    Process finished with exit code 0
    
    ```

最后得到的指标，虽然与原主有些差别，但还是可以的。





## 预测结果

- **这是在本机上跑的，因算力有限，设置参数与up主跟的有出入。**

#### best_epoch_weights.pth model

来看看，这就是在最好的权重下预测的结果

![image-20220719205503220](C:\Users\Happy\AppData\Roaming\Typora\typora-user-images\image-20220719205503220.png)



```python
D:\softwear_dl\anaconda\envs\torch1.10\python.exe D:/shuqikaohe/yolov5-pytorch-main/predict.py
logs/best_epoch_weights.pth model, and classes loaded.
Configurations:
----------------------------------------------------------------------
|                     keys |                                   values|
----------------------------------------------------------------------
|               model_path |              logs/best_epoch_weights.pth|
|             classes_path |               model_data/voc_classes.txt|
|             anchors_path |              model_data/yolo_anchors.txt|
|             anchors_mask |        [[6, 7, 8], [3, 4, 5], [0, 1, 2]]|
|              input_shape |                               [640, 640]|
|                 backbone |                               cspdarknet|
|                      phi |                                        s|
|               confidence |                                      0.5|
|                  nms_iou |                                      0.3|
|          letterbox_image |                                     True|
|                     cuda |                                     True|
----------------------------------------------------------------------
Input image filename:img\street.jpg
b'bicycle 0.90' 720 775 1040 1243
b'car 0.84' 583 654 773 974
b'person 0.89' 545 76 957 245
b'person 0.86' 502 913 999 1146
b'person 0.82' 543 438 863 547
b'person 0.74' 524 521 863 640
```



#### last_epoch_weights.pth model

这个是在最后一个权重下的预测

![image-20220719205819501](C:\Users\Happy\AppData\Roaming\Typora\typora-user-images\image-20220719205819501.png)

```python
D:\softwear_dl\anaconda\envs\torch1.10\python.exe D:/shuqikaohe/yolov5-pytorch-main/predict.py
logs/last_epoch_weights.pth model, and classes loaded.
Configurations:
----------------------------------------------------------------------
|                     keys |                                   values|
----------------------------------------------------------------------
|               model_path |              logs/last_epoch_weights.pth|
|             classes_path |               model_data/voc_classes.txt|
|             anchors_path |              model_data/yolo_anchors.txt|
|             anchors_mask |        [[6, 7, 8], [3, 4, 5], [0, 1, 2]]|
|              input_shape |                               [640, 640]|
|                 backbone |                               cspdarknet|
|                      phi |                                        s|
|               confidence |                                      0.5|
|                  nms_iou |                                      0.3|
|          letterbox_image |                                     True|
|                     cuda |                                     True|
----------------------------------------------------------------------
Input image filename:img\street.jpg
b'bicycle 0.90' 720 774 1039 1243
b'car 0.84' 583 652 773 973
b'person 0.88' 549 72 947 251
b'person 0.86' 502 911 999 1146
b'person 0.83' 543 438 862 547
b'person 0.74' 525 521 862 639
```



#### model_data/yolov5_s.pth model

- **注：没有可比性，只是单纯对照看看差距，给我优化的动力**

下面的这个是up主默认的coco数据集下的权值文件得到的预测。

![image-20220719211020704](C:\Users\Happy\AppData\Roaming\Typora\typora-user-images\image-20220719211020704.png)

```python
D:\softwear_dl\anaconda\envs\torch1.10\python.exe D:/shuqikaohe/yolov5-pytorch-main/predict.py
model_data/yolov5_s.pth model, and classes loaded.
Configurations:
----------------------------------------------------------------------
|                     keys |                                   values|
----------------------------------------------------------------------
|               model_path |                  model_data/yolov5_s.pth|
|             classes_path |              model_data/coco_classes.txt|
|             anchors_path |              model_data/yolo_anchors.txt|
|             anchors_mask |        [[6, 7, 8], [3, 4, 5], [0, 1, 2]]|
|              input_shape |                               [640, 640]|
|                 backbone |                               cspdarknet|
|                      phi |                                        s|
|               confidence |                                      0.5|
|                  nms_iou |                                      0.4|
|          letterbox_image |                                     True|
|                     cuda |                                     True|
----------------------------------------------------------------------
Input image filename:img\street.jpg
b'person 0.90' 550 69 940 279
b'person 0.88' 506 913 994 1144
b'person 0.87' 519 509 854 671
b'person 0.80' 540 438 858 545
b'person 0.78' 566 384 697 424
b'person 0.53' 580 208 693 263
b'bicycle 0.90' 714 781 1029 1250
b'car 0.86' 585 657 771 964
b'car 0.81' 610 1 678 49
b'car 0.69' 545 584 717 797
```



至此，baseline的模型就跑完了，开始疯狂魔改吧！



## 补充

- 后面在服务器上重新跑了baseline，模型结果在save_model这个文件里。但是忘记保存一些数据了。
