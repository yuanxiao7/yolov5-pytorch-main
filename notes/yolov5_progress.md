

## 前言

这个文件夹是用来完成小编的一次考核的，随着进程的深入，小编会不断地更新readme文件，把我整个任务内容，按序理清。



## 项目来源

-   https://github.com/bubbliiiing/yolov5-pytorch

这个目标检测项目是从b导得GitHub上fork的 ，采用的使yolov5.0版本，当然代码经过b导的一定封装，与官方源码大同小异。



## 目的

因为小编要完成一项考核，考核允许使用baseline进行优化改进，然后就选了b导的yolov5-v5.0作为baseline，然后理解baseline的工作，并做一定的修改，融入自己的理解，优化模型，web部署等。

----



## 过程



7-13日

环境配置等完成，理解主要相关概念，并开始跑训练，由于一开始没设置图片的存储位置，后面迁移的时候没有完整的迁移过去，导致开始训练时出现错误，后面查询了一番弄了两天，发现并重新下载图片，后面就开始跑训练，本机第一次跑，耗时两天半左右。100个epoch收敛。从零开始训练的，效果并不是很好。



7月17日

因为算力问题，此时本机还没跑完，所以开始在服务器上配置环境跑训练，由于服务器是linux环境，稍稍学了一些Ubuntu的指令，然后我就在服务器上跑，参数于b导给的差不多，跑完以后的道德baseline在测试集上的map达到83.10%，检测效果还好，但相对于预训练模型就差很多。



7月21日

两天前跑完baseline，今天想再次训练，发生了报错，说cuda版本问题，查看了环境，版本之间对应，并没有什么问题，搜了各种解答都没有用，因为我肯定我配置的环境的是没问题的，所以并没有重新下载配置，后面问学长，学长查了，发现我的conda list 和pip list并不是一致的，pip list对应的似乎是conda 默认的base环境，于是就敲命令卸载torchvision重新安装，跑训练，发现还是原来的环境，pip list 也没有改变，后面直接在本地下载上传文件夹，后面再次安装，最后终于配置成功。



7月23日

今天开始进行trick修改，激活函数组件比较简单，于是我就看博客，看论文，了解一些激活函数，silu函数的口碑很好，但是计算程度高，于是我就把他改成了hard_silu，后面map确实和论文中说的一样，与silu相差不大，但是他的召回率很低，不过训练速度一个epoch比silu的快了近两分钟，后面在旷视的一篇paper里面，了解到了frelu，专门针对视觉任务的激活函数，消除激活函数空间不敏感，并在imagenet和coco上做了实验，得到了很好的实验结果，于是我就将其用到我的网络里面。



7月30日

开始学习注意力集中机制，并且按作息上班（之前有点摆，控制一下），了解一下transformer，incode decode以及k q v等。



8月1日

深入学习SE CBAM ECA三个注意力模块，并开始做实验。因为训练用的是分布式训练，小伙伴也用，然后我的报错了，system error，还有被占用等，实在是整蒙了，又找谢学长，弄了几个小时，结果还是不行，环境remake，重开，换端口，消了一个bug，但主要的bug还在，寄，没能解决，只能用dp训练了，速度也还可以了，第二天尝试了一下，结果发现，ddp可以用了，很奇怪，后面才知道，小伙伴用ddp训练的效果很差，于是他就没有用了，后面再尝试，结果是当分别用两张卡训练时，只能一个ddp，但是可以ddp和dp，或者dp和dp，不清楚其内在原理了，知道怎么用就好。后面总会知道的。



8月6日

整理训练结果，梳理网络流程，了解一些数据增强，后面因为想要改loss，看看focal loss是不是能很好地解决正负样本的不均衡的问题，因为之前v3paper作者说，focal loss对他的作用没有体现，至少他的实验中是这样的，但是网上有人说可以提升精度，于是我还是觉定自己尝试一遍，



8月7日

对yolo head最终的输出有疑惑，我不能说出矩阵中每一个值的含义，于是就去找学姐，但是学姐的跟我的想法又有一些出入，后面学长加入一起讨论，还一起弄了实验，debug，最后了解了代码矩阵的运算，但是我还是没有衔接上来，还需要多看一些博客才行，很多东西还是要自己多找才知道。第二天，找了很多资料，看到一篇博客，讲的很好，还跟着博客链接到了you tube不知是哪一国语言，但是讲得很透彻，虽然翻译很拉跨，但我还是理解了，后面，在我们的优酷上看到江大白老师讲的很好，还有up科技猛兽。最后我理解了输出的矩阵代表的含义。



8月8日

今天，修改置信度的loss，做实验，跑训练，着重看了mosaic数据增强实现原理。



8月9日

整理昨天的数据，做个精简PPT，因为小麦学长说PPT不能太多字，所以我把开始的写的那些都隐藏起来看，后面也只是简单的图示而已，晚上答辩，有点紧张，不会说，最后被问到了CA模块最后的矩阵乘法运算，因为我是把他们shape还原到原来的shape才相乘的，但刚好学长他用的是利用矩阵乘法的，所以我没答上来，而我看的时候，我也以为他是还原回去在相乘的，所以，我并没有细看原来的过程，大至了解到它可以增强移动网络学习特征的表达能力，可用于任意两张特征图之间进行宽度和高度的特征提取，最后相乘拼接。看来，用到的模块还是要好好了解，先看官方的解释，在看其他博主的观点，在融合自己的看法，像之前那样详细了解了模块后再去使用会更好。（不要偷懒！）



8月9日

今天整理笔记，梳理一下文件，做文化课作业（呜呜呜，头歌真好...）







